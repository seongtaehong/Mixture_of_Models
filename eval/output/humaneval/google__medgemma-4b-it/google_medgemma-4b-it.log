INFO 05-23 22:49:45 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 05-23 22:49:46 [__init__.py:239] Automatically detected platform cuda.
2025-05-23:22:49:50 INFO     [__main__:440] Selected Tasks: ['humaneval_instruct']
2025-05-23:22:49:50 INFO     [evaluator:185] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-05-23:22:49:50 INFO     [evaluator:223] Initializing vllm model, with arguments: {'pretrained': 'google/medgemma-4b-it', 'tensor_parallel_size': 1, 'dtype': 'auto', 'gpu_memory_utilization': 0.7}
INFO 05-23 22:50:00 [config.py:717] This model supports multiple tasks: {'generate', 'classify', 'score', 'reward', 'embed'}. Defaulting to 'generate'.
INFO 05-23 22:50:00 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 05-23 22:50:04 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='google/medgemma-4b-it', speculative_config=None, tokenizer='google/medgemma-4b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=1234, served_model_name=google/medgemma-4b-it, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
2025-05-23 22:50:07,288 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
WARNING 05-23 22:50:07 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fce315396a0>
INFO 05-23 22:50:09 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 05-23 22:50:09 [cuda.py:221] Using Flash Attention backend on V1 engine.
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
INFO 05-23 22:50:20 [topk_topp_sampler.py:44] Currently, FlashInfer top-p & top-k sampling sampler is disabled because FlashInfer>=v0.2.3 is not backward compatible. Falling back to the PyTorch-native implementation of top-p & top-k sampling.
INFO 05-23 22:50:21 [gpu_model_runner.py:1329] Starting to load model google/medgemma-4b-it...
INFO 05-23 22:50:23 [config.py:3614] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
INFO 05-23 22:50:26 [weight_utils.py:265] Using model weights format ['*.safetensors']
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.17s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.49s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.44s/it]

INFO 05-23 22:50:30 [loader.py:458] Loading weights took 3.02 seconds
INFO 05-23 22:50:30 [gpu_model_runner.py:1347] Model loading took 8.5832 GiB and 8.662170 seconds
INFO 05-23 22:50:30 [gpu_model_runner.py:1620] Encoder cache will be initialized with a budget of 8192 tokens, and profiled with 32 image items of the maximum feature size.
INFO 05-23 22:50:47 [backends.py:420] Using cache directory: /mnt/raid6/hst/.cache/vllm/torch_compile_cache/af98f58bd3/rank_0_0 for vLLM's torch.compile
INFO 05-23 22:50:47 [backends.py:430] Dynamo bytecode transform time: 11.00 s
INFO 05-23 22:51:29 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 40.576 s
INFO 05-23 22:51:30 [monitor.py:33] torch.compile takes 11.00 s in total
INFO 05-23 22:51:31 [kv_cache_utils.py:634] GPU KV cache size: 151,792 tokens
INFO 05-23 22:51:31 [kv_cache_utils.py:637] Maximum concurrency for 131,072 tokens per request: 1.16x
INFO 05-23 22:52:59 [gpu_model_runner.py:1686] Graph capturing finished in 88 secs, took 1.98 GiB
INFO 05-23 22:53:00 [core.py:159] init engine (profile, create kv cache, warmup model) took 149.77 seconds
INFO 05-23 22:53:00 [core_client.py:439] Core engine process 0 ready.
2025-05-23:22:53:03 INFO     [models.vllm_causallms:138] Found 'gemma' in model name, a BOS token will be used as Gemma series models underperform without it.
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
2025-05-23:22:53:17 INFO     [evaluator:286] humaneval_instruct: Using gen_kwargs: {'until': ['\nclass', '\ndef', '\n#', '\nif', '\nprint'], 'max_gen_toks': 1024, 'do_sample': False}
2025-05-23:22:53:17 INFO     [api.task:434] Building contexts for humaneval_instruct on rank 0...
  0%|          | 0/164 [00:00<?, ?it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 129/164 [00:00<00:00, 1285.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 164/164 [00:00<00:00, 1295.79it/s]
2025-05-23:22:53:17 INFO     [evaluator_utils:206] Task: ConfigurableTask(task_name=humaneval_instruct,output_type=generate_until,num_fewshot=0,num_samples=164); document 0; context prompt (starting on next line):    
Write a solution to the following problem and make sure that it passes the tests:
```from typing import List


def has_close_elements(numbers: List[float], threshold: float) -> bool:
    """ Check if in given list of numbers, are any two numbers closer to each other than
    given threshold.
    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)
    False
    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)
    True
    """
 Here is the completed function:
```python
from typing import List


def has_close_elements(numbers: List[float], threshold: float) -> bool:
    """ Check if in given list of numbers, are any two numbers closer to each other than
    given threshold.
    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)
    False
    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)
    True
    """


(end of prompt on previous line)
target string or answer choice index (starting on next line):


METADATA = {
    'author': 'jt',
    'dataset': 'test'
}


def check(candidate):
    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True
    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False
    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True
    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False
    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True
    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True
    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False


check(has_close_elements)
(end of target on previous line)
2025-05-23:22:53:17 INFO     [evaluator_utils:210] Request: Instance(request_type='generate_until', doc={'task_id': 'HumanEval/0', 'prompt': 'from typing import List\n\n\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\n    """ Check if in given list of numbers, are any two numbers closer to each other than\n    given threshold.\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n    False\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n    True\n    """\n', 'canonical_solution': '    for idx, elem in enumerate(numbers):\n        for idx2, elem2 in enumerate(numbers):\n            if idx != idx2:\n                distance = abs(elem - elem2)\n                if distance < threshold:\n                    return True\n\n    return False\n', 'test': "\n\nMETADATA = {\n    'author': 'jt',\n    'dataset': 'test'\n}\n\n\ndef check(candidate):\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\n\n", 'entry_point': 'has_close_elements'}, arguments=('Write a solution to the following problem and make sure that it passes the tests:\n```from typing import List\n\n\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\n    """ Check if in given list of numbers, are any two numbers closer to each other than\n    given threshold.\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n    False\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n    True\n    """\n Here is the completed function:\n```python\nfrom typing import List\n\n\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\n    """ Check if in given list of numbers, are any two numbers closer to each other than\n    given threshold.\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n    False\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n    True\n    """\n\n', {'until': ['\nclass', '\ndef', '\n#', '\nif', '\nprint'], 'max_gen_toks': 1024, 'do_sample': False}), idx=0, metadata=('humaneval_instruct', 0, 1), resps=[], filtered_resps={}, task_name='humaneval_instruct', doc_id=0, repeats=1)
2025-05-23:22:53:17 INFO     [evaluator:559] Running generate_until requests
Running generate_until requests:   0%|          | 0/164 [00:00<?, ?it/s]
Processed prompts:   0%|          | 0/164 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts:   1%|          | 1/164 [00:03<09:14,  3.40s/it, est. speed input: 99.59 toks/s, output: 1.76 toks/s][A
Processed prompts:   4%|â–Ž         | 6/164 [00:03<01:09,  2.28it/s, est. speed input: 342.02 toks/s, output: 9.08 toks/s][A
Processed prompts:   5%|â–Œ         | 9/164 [00:03<00:41,  3.73it/s, est. speed input: 628.14 toks/s, output: 18.10 toks/s][A
Processed prompts:   8%|â–Š         | 13/164 [00:03<00:25,  6.04it/s, est. speed input: 792.13 toks/s, output: 29.68 toks/s][A
Processed prompts:  10%|â–‰         | 16/164 [00:04<00:20,  7.26it/s, est. speed input: 977.20 toks/s, output: 42.99 toks/s][A
Processed prompts:  12%|â–ˆâ–        | 19/164 [00:04<00:17,  8.10it/s, est. speed input: 1097.73 toks/s, output: 57.56 toks/s][A
Processed prompts:  13%|â–ˆâ–Ž        | 22/164 [00:04<00:13, 10.26it/s, est. speed input: 1220.63 toks/s, output: 75.80 toks/s][A
Processed prompts:  16%|â–ˆâ–Œ        | 26/164 [00:04<00:10, 12.56it/s, est. speed input: 1374.43 toks/s, output: 101.20 toks/s][A
Processed prompts:  18%|â–ˆâ–Š        | 29/164 [00:04<00:09, 14.68it/s, est. speed input: 1487.11 toks/s, output: 122.21 toks/s][A
Processed prompts:  20%|â–ˆâ–ˆ        | 33/164 [00:04<00:07, 18.43it/s, est. speed input: 1771.46 toks/s, output: 154.18 toks/s][A
Processed prompts:  22%|â–ˆâ–ˆâ–       | 36/164 [00:05<00:06, 18.79it/s, est. speed input: 1910.83 toks/s, output: 176.58 toks/s][A
Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 44/164 [00:05<00:04, 28.39it/s, est. speed input: 2292.92 toks/s, output: 245.72 toks/s][A
Processed prompts:  30%|â–ˆâ–ˆâ–‰       | 49/164 [00:05<00:03, 32.48it/s, est. speed input: 2499.91 toks/s, output: 290.27 toks/s][A
Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 53/164 [00:05<00:03, 33.89it/s, est. speed input: 2695.55 toks/s, output: 325.74 toks/s][A
Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 59/164 [00:05<00:02, 39.98it/s, est. speed input: 2967.07 toks/s, output: 383.67 toks/s][A
Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 65/164 [00:05<00:02, 45.09it/s, est. speed input: 3200.25 toks/s, output: 442.16 toks/s][A
Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 73/164 [00:05<00:01, 50.46it/s, est. speed input: 3602.46 toks/s, output: 523.51 toks/s][A
Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 79/164 [00:05<00:01, 46.20it/s, est. speed input: 3839.16 toks/s, output: 580.99 toks/s][A
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 84/164 [00:06<00:01, 42.23it/s, est. speed input: 4020.64 toks/s, output: 628.44 toks/s][A
Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 92/164 [00:06<00:01, 49.51it/s, est. speed input: 4275.90 toks/s, output: 717.78 toks/s][A
Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 98/164 [00:06<00:01, 40.17it/s, est. speed input: 4452.88 toks/s, output: 774.19 toks/s][A
Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 104/164 [00:06<00:01, 43.80it/s, est. speed input: 4711.25 toks/s, output: 846.27 toks/s][A
Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 109/164 [00:06<00:01, 42.90it/s, est. speed input: 4897.98 toks/s, output: 902.40 toks/s][A
Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 114/164 [00:06<00:01, 38.41it/s, est. speed input: 5026.99 toks/s, output: 955.90 toks/s][A
Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 119/164 [00:07<00:01, 25.50it/s, est. speed input: 4984.20 toks/s, output: 986.83 toks/s][A
Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 123/164 [00:07<00:01, 23.90it/s, est. speed input: 5019.62 toks/s, output: 1028.24 toks/s][A
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 126/164 [00:07<00:02, 17.94it/s, est. speed input: 4954.00 toks/s, output: 1038.53 toks/s][A
Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 129/164 [00:07<00:02, 15.59it/s, est. speed input: 4944.98 toks/s, output: 1059.81 toks/s][A
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 131/164 [00:08<00:02, 15.53it/s, est. speed input: 4954.51 toks/s, output: 1081.93 toks/s][A
Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 135/164 [00:08<00:01, 19.37it/s, est. speed input: 5083.82 toks/s, output: 1147.41 toks/s][A
Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 138/164 [00:08<00:01, 14.20it/s, est. speed input: 4956.16 toks/s, output: 1158.81 toks/s][A
Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 140/164 [00:08<00:01, 14.25it/s, est. speed input: 5005.66 toks/s, output: 1183.89 toks/s][A
Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 142/164 [00:10<00:04,  4.81it/s, est. speed input: 4411.04 toks/s, output: 1068.42 toks/s][A
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 144/164 [00:15<00:15,  1.26it/s, est. speed input: 2961.03 toks/s, output: 757.19 toks/s] [A
Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 145/164 [00:17<00:18,  1.01it/s, est. speed input: 2634.01 toks/s, output: 702.22 toks/s][A
Processed prompts:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 146/164 [00:21<00:27,  1.53s/it, est. speed input: 2155.77 toks/s, output: 607.25 toks/s][A
Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 147/164 [00:24<00:31,  1.86s/it, est. speed input: 1913.69 toks/s, output: 570.59 toks/s][A
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 159/164 [00:24<00:02,  2.33it/s, est. speed input: 2098.03 toks/s, output: 1063.24 toks/s][AProcessed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 164/164 [00:24<00:00,  6.61it/s, est. speed input: 2124.41 toks/s, output: 1269.51 toks/s]
Running generate_until requests:   1%|          | 1/164 [00:24<1:07:30, 24.85s/it]Running generate_until requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 164/164 [00:24<00:00,  6.60it/s]
fatal: not a git repository (or any parent up to mount point /mnt)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-05-23:22:54:17 INFO     [loggers.evaluation_tracker:209] Saving results aggregated
2025-05-23:22:54:17 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: humaneval_instruct
vllm (pretrained=google/medgemma-4b-it,tensor_parallel_size=1,dtype=auto,gpu_memory_utilization=0.7), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto
|      Tasks       |Version|  Filter   |n-shot|Metric|   |Value |   |Stderr|
|------------------|------:|-----------|-----:|------|---|-----:|---|-----:|
|humaneval_instruct|      2|create_test|     0|pass@1|   |0.0061|Â±  |0.0061|

